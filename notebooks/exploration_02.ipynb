{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3c6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 18:50:33.705966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-27 18:50:33.705989: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Masking, Dense, LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a start, let's use the imdb reviews dataset\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fab414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(percentage_of_sentences=None):\n",
    "    # Load the data\n",
    "    (sentences_train, y_train), (sentences_test, y_test) = imdb.load_data()\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(sentences_train))\n",
    "        sentences_train = sentences_train[:len_train]\n",
    "        y_train = y_train[:len_train]\n",
    "        \n",
    "        len_test = int(percentage_of_sentences/100*len(sentences_test))\n",
    "        sentences_test = sentences_test[:len_test]\n",
    "        y_test = y_test[:len_test]\n",
    "            \n",
    "    # Load the {interger: word} representation\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    for i, w in enumerate(['<PAD>', '<START>', '<UNK>', '<UNUSED>']):\n",
    "        word_to_id[w] = i\n",
    "\n",
    "    id_to_word = {v:k for k, v in word_to_id.items()}\n",
    "\n",
    "    # Convert the list of integers to list of words (str)\n",
    "    X_train = [' '.join([id_to_word[_] for _ in sentence[1:]]) for sentence in sentences_train]\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "\n",
    "### Just run this cell to load the data\n",
    "data = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d97a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(sentence, length=20):\n",
    "    '''\n",
    "    returns a tuple containing:\n",
    "    - a sentence (a string)\n",
    "    - the word immediately following that sentence\n",
    "    '''\n",
    "    words = sentence.split()\n",
    "    # return None if the sentence is too short\n",
    "    if len(words) <= length:\n",
    "        return None\n",
    "    # pick a random part of the sentence\n",
    "    first_word_idx = np.random.randint(0, len(words) - length)\n",
    "    # build X (a part of the sentence) and y (the word immediately following X)\n",
    "    X = words[first_word_idx : first_word_idx + length]\n",
    "    y = words[first_word_idx + length]\n",
    "    # return X and y\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03db5e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['fly',\n",
       "  'fishing',\n",
       "  'was',\n",
       "  'amazing',\n",
       "  'really',\n",
       "  'cried',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  'it',\n",
       "  'was',\n",
       "  'so',\n",
       "  'sad',\n",
       "  'and',\n",
       "  'you',\n",
       "  'know',\n",
       "  'what',\n",
       "  'they',\n",
       "  'say',\n",
       "  'if'],\n",
       " 'you')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output of the function\n",
    "get_X_y(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a0545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sentences, number_of_samples = 50000):\n",
    "    '''\n",
    "    creates a dataset (X and y) made of number_of_samples observations\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    indices = np.random.randint(0, len(sentences), size=number_of_samples)\n",
    "    # call get_X_y number_of_samples times\n",
    "    for idx in indices:\n",
    "        ret = get_X_y(sentences[idx])\n",
    "        if ret is None:\n",
    "            continue\n",
    "        xi, yi = ret\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc40a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba41d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46774264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34969, 14988, 34969, 14988)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a44e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a word2vec model\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=20, min_count=10, window=10)\n",
    "wv = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd2eb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check embedding size\n",
    "wv[\"movie\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0873cd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.8951712846755981),\n",
       " ('flick', 0.8017658591270447),\n",
       " ('thing', 0.7820267677307129),\n",
       " ('show', 0.7294928431510925),\n",
       " ('episode', 0.7083120942115784),\n",
       " ('shame', 0.7069810032844543),\n",
       " ('crap', 0.6890944838523865),\n",
       " ('everything', 0.6858541369438171),\n",
       " ('remake', 0.66377192735672),\n",
       " ('fun', 0.6494260430335999)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a8ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5588408 , -2.3808193 ,  3.109312  , -1.3963088 , -0.86325824,\n",
       "        5.4049573 , -1.891605  ,  1.2675676 ,  0.6402838 , -2.7112646 ,\n",
       "       -0.8533588 , -1.773583  ,  0.89358914, -1.0737842 ,  1.3911701 ,\n",
       "       -0.57071954,  3.5721765 ,  1.614322  , -1.8713921 , -0.13573104],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv[\"movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb05700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 1.0),\n",
       " ('film', 0.8951712250709534),\n",
       " ('flick', 0.8017658591270447),\n",
       " ('thing', 0.7820267677307129),\n",
       " ('show', 0.7294928431510925),\n",
       " ('episode', 0.7083120942115784),\n",
       " ('shame', 0.7069809436798096),\n",
       " ('crap', 0.6890944838523865),\n",
       " ('everything', 0.6858541369438171),\n",
       " ('remake', 0.6637718677520752)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(wv[\"movie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7559387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5350"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(wv.key_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8b1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=40)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64b1973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check X_train_pad and W_test_pad\n",
    "type(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcba7609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34969, 40, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf575647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14988, 40, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59b586ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8614a661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34969"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ca5e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14988"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64407916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check y_train and y_test\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce6bf711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34969"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ea5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123223426463439"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many words from y_train are in wv\n",
    "sum([word in wv for word in y_train]) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9227958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133973845743262"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many words from y_test are in wv\n",
    "sum([word in wv for word in y_test]) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c677717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34969, 40, 20), (14988, 40, 20), 34969, 14988)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape, X_test_pad.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac0c0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter X_train_pad (and X_test_pad) to keep only the observations for which y_train (and y_test) is in wv\n",
    "mask_train = [word in wv for word in y_train]\n",
    "X_train_pad = X_train_pad[mask_train, :, :]\n",
    "y_train = [word for word in y_train if word in wv]\n",
    "mask_test = [word in wv for word in y_test]\n",
    "X_test_pad = X_test_pad[mask_test, :, :]\n",
    "y_test = [word for word in y_test if word in wv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8daa1807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31903, 40, 20), (13690, 40, 20), 31903, 13690)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape, X_test_pad.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e0205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform y_train and y_test into vectors\n",
    "y_train_vec = np.array([wv[word] for word in y_train])\n",
    "y_test_vec = np.array([wv[word] for word in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0261f242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31903, 20), (13690, 20))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vec.shape, y_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7f516c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29732156, -1.3444813 ,  1.3773881 ,  1.7681061 ,  0.50167847,\n",
       "        1.2660348 ,  2.9678817 , -0.7449177 , -0.1939574 ,  0.08014315,\n",
       "       -0.6463477 ,  1.7013825 ,  3.7770576 ,  2.0104382 , -0.78710914,\n",
       "       -0.25413918,  0.17603111,  2.5254753 , -5.7983294 ,  0.7528816 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b98eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 18:50:47.148035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-27 18:50:47.148070: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 18:50:47.148091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (think): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 18:50:47.148344: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking())\n",
    "    model.add(GRU(20, activation=\"tanh\", return_sequences=True))\n",
    "    model.add(GRU(16, activation=\"tanh\", return_sequences=False))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(20, activation=\"linear\"))\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95d2eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1396/1396 [==============================] - 56s 33ms/step - loss: 0.9672 - mse: 1.9302 - val_loss: 0.9548 - val_mse: 1.8940\n",
      "Epoch 2/100\n",
      "1396/1396 [==============================] - 45s 32ms/step - loss: 0.9518 - mse: 1.8762 - val_loss: 0.9469 - val_mse: 1.8623\n",
      "Epoch 3/100\n",
      "1396/1396 [==============================] - 45s 32ms/step - loss: 0.9461 - mse: 1.8568 - val_loss: 0.9422 - val_mse: 1.8439\n",
      "Epoch 4/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9408 - mse: 1.8396 - val_loss: 0.9373 - val_mse: 1.8289\n",
      "Epoch 5/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9350 - mse: 1.8236 - val_loss: 0.9344 - val_mse: 1.8300\n",
      "Epoch 6/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9306 - mse: 1.8126 - val_loss: 0.9300 - val_mse: 1.8152\n",
      "Epoch 7/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9272 - mse: 1.8038 - val_loss: 0.9277 - val_mse: 1.8046\n",
      "Epoch 8/100\n",
      "1396/1396 [==============================] - 45s 32ms/step - loss: 0.9247 - mse: 1.7970 - val_loss: 0.9287 - val_mse: 1.8202\n",
      "Epoch 9/100\n",
      "1396/1396 [==============================] - 45s 32ms/step - loss: 0.9227 - mse: 1.7921 - val_loss: 0.9250 - val_mse: 1.7998\n",
      "Epoch 10/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9212 - mse: 1.7877 - val_loss: 0.9259 - val_mse: 1.8062\n",
      "Epoch 11/100\n",
      "1396/1396 [==============================] - 44s 32ms/step - loss: 0.9206 - mse: 1.7859 - val_loss: 0.9248 - val_mse: 1.7832\n",
      "Epoch 12/100\n",
      "1396/1396 [==============================] - 47s 33ms/step - loss: 0.9197 - mse: 1.7829 - val_loss: 0.9238 - val_mse: 1.7915\n",
      "Epoch 13/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9191 - mse: 1.7811 - val_loss: 0.9239 - val_mse: 1.7871\n",
      "Epoch 14/100\n",
      "1396/1396 [==============================] - 47s 33ms/step - loss: 0.9185 - mse: 1.7791 - val_loss: 0.9253 - val_mse: 1.8029\n",
      "Epoch 15/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9179 - mse: 1.7774 - val_loss: 0.9238 - val_mse: 1.7821\n",
      "Epoch 16/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9174 - mse: 1.7746 - val_loss: 0.9238 - val_mse: 1.7903\n",
      "Epoch 17/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9166 - mse: 1.7726 - val_loss: 0.9247 - val_mse: 1.7956\n",
      "Epoch 18/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9161 - mse: 1.7711 - val_loss: 0.9243 - val_mse: 1.7767\n",
      "Epoch 19/100\n",
      "1396/1396 [==============================] - 47s 34ms/step - loss: 0.9157 - mse: 1.7697 - val_loss: 0.9238 - val_mse: 1.7872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb465fe0f70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train_vec, \n",
    "          batch_size = 16,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e411634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/428 [==============================] - 3s 7ms/step - loss: 0.9244 - mse: 1.8006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9244070053100586, 1.8006491661071777]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad, y_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8d613df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['film',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'appeal',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deepest',\n",
       "  'darkest',\n",
       "  'parts',\n",
       "  'of',\n",
       "  'our',\n",
       "  'being',\n",
       "  'and',\n",
       "  'if',\n",
       "  'the',\n",
       "  'movie',\n",
       "  \"wasn't\",\n",
       "  'so',\n",
       "  'boring',\n",
       "  'this'],\n",
       " 'film')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bdf9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad[:1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1349dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.5774165 , -1.1677458 ,  1.5750263 , -0.34980276, -0.34538257,\n",
       "         0.78398883, -0.15256947,  1.0021098 , -0.2668214 , -0.7212622 ,\n",
       "         0.48466468, -0.5917636 ,  0.4909073 , -0.47223043,  0.80382305,\n",
       "        -0.74209684,  2.4024122 ,  1.0991554 , -0.66273177,  0.05816066]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_pad[:1, :, :])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e29d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af869a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flick', 0.8876231908798218),\n",
       " ('picture', 0.864725649356842),\n",
       " ('film', 0.8458181023597717),\n",
       " ('shame', 0.8452079892158508),\n",
       " ('entertaining', 0.83879154920578),\n",
       " ('script', 0.8369504809379578),\n",
       " ('movie', 0.836172878742218),\n",
       " ('terrible', 0.8344402313232422),\n",
       " ('case', 0.8285846710205078),\n",
       " ('overall', 0.8186780214309692)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea9a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to append y_pred to X_test[0] and predict over and over to predict multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c1fe78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flick'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word = wv.similar_by_vector(y_pred[0], topn=1)[0][0]\n",
    "new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4bb23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[0][1:]\n",
    "X_new.append(new_word)\n",
    "X_new = [X_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1af27b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48528867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new[0]), len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5559ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_embed = embedding(word2vec, X_new)\n",
    "X_new_pad = pad_sequences(X_new_embed, dtype='float32', padding='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22dbaab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "106476fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_new_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfb77796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('holes', 0.9149927496910095),\n",
       " ('entertainment', 0.9103526473045349),\n",
       " ('mood', 0.9066997170448303),\n",
       " ('watchable', 0.9061463475227356),\n",
       " ('dated', 0.9026296734809875),\n",
       " ('missed', 0.9013277292251587),\n",
       " ('scary', 0.9009276032447815),\n",
       " ('disbelief', 0.9006526470184326),\n",
       " ('subtitles', 0.9005107879638672),\n",
       " ('remotely', 0.8999220132827759)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae8f387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"he doesn't realize that his behavior should change and continues to act as he had before he listens to rap music sings along and plays the stereotypical part of an urban black man the real humor in this flick pc disbelief entirely threw fairly ironic ironic ironic ironic\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's put this into a function\n",
    "def repeat_prediction(sentence, repetition=10):\n",
    "    new_sentence = sentence\n",
    "    X = sentence.split()\n",
    "    for i in range(repetition):\n",
    "        X_embed = embedding(word2vec, [X])\n",
    "        X_pad = pad_sequences(X_embed, dtype='float32', padding='post', maxlen=40)\n",
    "        y_pred = model.predict(X_pad)\n",
    "        new_word = wv.similar_by_vector(y_pred[0], topn=1)[0][0]\n",
    "        X.pop(0)\n",
    "        X.append(new_word)\n",
    "        new_sentence += \" \" + new_word\n",
    "    return new_sentence\n",
    "\n",
    "sentence = \"he doesn't realize that his behavior should change and continues to act as he had before he listens to rap music sings along and plays the stereotypical part of an urban black man the real humor in this\"\n",
    "new_sentence = repeat_prediction(sentence)\n",
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2864956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i like this movie and the actor dated nevertheless curious dated entirely offensive entirely disbelief entirely disbelief'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"i like this movie and the actor\"\n",
    "new_sentence = repeat_prediction(sentence)\n",
    "new_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
