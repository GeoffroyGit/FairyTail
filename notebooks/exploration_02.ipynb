{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3c6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 17:21:44.692751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-27 17:21:44.692776: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Masking, Dense, LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a start, let's use the imdb reviews dataset\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fab414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(percentage_of_sentences=None):\n",
    "    # Load the data\n",
    "    (sentences_train, y_train), (sentences_test, y_test) = imdb.load_data()\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(sentences_train))\n",
    "        sentences_train = sentences_train[:len_train]\n",
    "        y_train = y_train[:len_train]\n",
    "        \n",
    "        len_test = int(percentage_of_sentences/100*len(sentences_test))\n",
    "        sentences_test = sentences_test[:len_test]\n",
    "        y_test = y_test[:len_test]\n",
    "            \n",
    "    # Load the {interger: word} representation\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    for i, w in enumerate(['<PAD>', '<START>', '<UNK>', '<UNUSED>']):\n",
    "        word_to_id[w] = i\n",
    "\n",
    "    id_to_word = {v:k for k, v in word_to_id.items()}\n",
    "\n",
    "    # Convert the list of integers to list of words (str)\n",
    "    X_train = [' '.join([id_to_word[_] for _ in sentence[1:]]) for sentence in sentences_train]\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "\n",
    "### Just run this cell to load the data\n",
    "data = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d97a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(sentence, length=40):\n",
    "    '''\n",
    "    returns a tuple containing:\n",
    "    - a sentence (a string)\n",
    "    - the word immediately following that sentence\n",
    "    '''\n",
    "    words = sentence.split()\n",
    "    # return None if the sentence is too short\n",
    "    if len(words) <= length:\n",
    "        return None\n",
    "    # pick a random part of the sentence\n",
    "    first_word_idx = np.random.randint(0, len(words) - length)\n",
    "    # build X (a part of the sentence) and y (the word immediately following X)\n",
    "    X = words[first_word_idx : first_word_idx + length]\n",
    "    y = words[first_word_idx + length]\n",
    "    # return X and y\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03db5e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['robert',\n",
       "  \"redford's\",\n",
       "  'is',\n",
       "  'an',\n",
       "  'amazing',\n",
       "  'actor',\n",
       "  'and',\n",
       "  'now',\n",
       "  'the',\n",
       "  'same',\n",
       "  'being',\n",
       "  'director',\n",
       "  \"norman's\",\n",
       "  'father',\n",
       "  'came',\n",
       "  'from',\n",
       "  'the',\n",
       "  'same',\n",
       "  'scottish',\n",
       "  'island',\n",
       "  'as',\n",
       "  'myself',\n",
       "  'so',\n",
       "  'i',\n",
       "  'loved',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'real',\n",
       "  'connection',\n",
       "  'with',\n",
       "  'this',\n",
       "  'film',\n",
       "  'the',\n",
       "  'witty',\n",
       "  'remarks',\n",
       "  'throughout',\n",
       "  'the'],\n",
       " 'film')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output of the function\n",
    "get_X_y(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a0545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sentences, number_of_samples = 10000):\n",
    "    '''\n",
    "    creates a dataset (X and y) made of number_of_samples observations\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    indices = np.random.randint(0, len(sentences), size=number_of_samples)\n",
    "    # call get_X_y number_of_samples times\n",
    "    for idx in indices:\n",
    "        ret = get_X_y(sentences[idx])\n",
    "        if ret is None:\n",
    "            continue\n",
    "        xi, yi = ret\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc40a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba41d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46774264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6939, 2974, 6939, 2974)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a44e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a word2vec model\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=60, min_count=10, window=10)\n",
    "wv = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd2eb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check embedding size\n",
    "wv[\"movie\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0873cd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thing', 0.9436944127082825),\n",
       " ('film', 0.9328452348709106),\n",
       " ('worst', 0.8986397385597229),\n",
       " ('really', 0.8773297071456909),\n",
       " (\"wasn't\", 0.8706840872764587),\n",
       " ('worth', 0.8684008121490479),\n",
       " ('entertaining', 0.8641366362571716),\n",
       " ('ever', 0.8624119758605957),\n",
       " ('watching', 0.8595168590545654),\n",
       " (\"isn't\", 0.8518555760383606)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a8ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26939258,  0.22727671,  1.6425986 , -0.46513474, -0.81536955,\n",
       "        0.07606534,  0.52022386,  1.217694  , -0.95508873, -0.18229   ,\n",
       "        2.0107858 , -0.01701614, -0.3375833 , -0.00599152, -0.38202333,\n",
       "       -1.2598183 ,  0.6614996 ,  0.3316515 , -0.8055477 , -1.8089521 ,\n",
       "       -0.444411  , -0.12864034,  1.1217287 ,  0.05814089, -0.02403587,\n",
       "       -0.10075924,  0.04603994,  0.0330493 , -0.4630286 , -0.28347018,\n",
       "       -1.0758255 ,  0.26436836,  0.369587  , -0.45169133, -0.15273842,\n",
       "        0.01122016, -0.8233154 , -1.1630796 , -0.38601926, -0.64197487,\n",
       "        0.29810837, -0.6036165 , -0.24657275, -0.07866705,  0.48859063,\n",
       "        0.505661  , -0.9897906 ,  0.06472152,  0.0919769 ,  0.41475278,\n",
       "        0.04984819, -0.02200857,  0.25209785, -0.23751783, -0.48187834,\n",
       "        0.33497384,  0.87743294,  0.04533954,  0.41354102, -1.3827277 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv[\"movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb05700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 0.9999998807907104),\n",
       " ('thing', 0.943694531917572),\n",
       " ('film', 0.9328452348709106),\n",
       " ('worst', 0.8986397385597229),\n",
       " ('really', 0.8773297071456909),\n",
       " (\"wasn't\", 0.8706841468811035),\n",
       " ('worth', 0.8684008121490479),\n",
       " ('entertaining', 0.8641366362571716),\n",
       " ('ever', 0.8624119758605957),\n",
       " ('watching', 0.8595169186592102)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(wv[\"movie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7559387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2589"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(wv.key_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8b1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=40)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64b1973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check X_train_pad and W_test_pad\n",
    "type(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcba7609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6939, 40, 60)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf575647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2974, 40, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59b586ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8614a661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6939"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ca5e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2974"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64407916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check y_train and y_test\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce6bf711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6939"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ea5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8684248450785416"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many words from y_train are in wv\n",
    "sum([word in wv for word in y_train]) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9227958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688634835238735"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many words from y_test are in wv\n",
    "sum([word in wv for word in y_test]) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c677717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6939, 40, 60), (2974, 40, 60), 6939, 2974)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape, X_test_pad.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac0c0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter X_train_pad (and X_test_pad) to keep only the observations for which y_train (and y_test) is in wv\n",
    "mask_train = [word in wv for word in y_train]\n",
    "X_train_pad = X_train_pad[mask_train, :, :]\n",
    "y_train = [word for word in y_train if word in wv]\n",
    "mask_test = [word in wv for word in y_test]\n",
    "X_test_pad = X_test_pad[mask_test, :, :]\n",
    "y_test = [word for word in y_test if word in wv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8daa1807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6026, 40, 60), (2584, 40, 60), 6026, 2584)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape, X_test_pad.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e0205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform y_train and y_test into vectors\n",
    "y_train_vec = np.array([wv[word] for word in y_train])\n",
    "y_test_vec = np.array([wv[word] for word in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0261f242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6026, 60), (2584, 60))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vec.shape, y_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7f516c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04372703,  0.22827551,  0.15656076,  0.05237848, -0.05006586,\n",
       "       -0.0986954 ,  0.15983543,  0.2943019 , -0.14251803, -0.06070546,\n",
       "        0.5778855 ,  0.13686685,  0.08449788, -0.44681913,  0.01979469,\n",
       "       -0.1957505 ,  0.26323652, -0.00643774, -0.482569  , -0.16440654,\n",
       "       -0.03104678, -0.29329532,  0.10434166,  0.23916727,  0.06357735,\n",
       "       -0.03900078, -0.0947843 ,  0.19263105, -0.15048622, -0.2338036 ,\n",
       "       -0.01798677, -0.52638173,  0.33945128, -0.06111382,  0.29359928,\n",
       "        0.17500456,  0.11996654, -0.3034498 , -0.36776918,  0.05197386,\n",
       "       -0.05260934,  0.00476697, -0.22259073, -0.14970438,  0.17256969,\n",
       "       -0.00386069, -0.08359666,  0.13787009, -0.11536425,  0.3996215 ,\n",
       "       -0.15150256,  0.05159961, -0.05135211,  0.33399057,  0.26028588,\n",
       "        0.24064623,  0.05033691,  0.05090418,  0.32481053, -0.4068299 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b98eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 17:21:53.252514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-27 17:21:53.252554: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 17:21:53.252594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (think): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 17:21:53.252974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking())\n",
    "    model.add(SimpleRNN(20, activation=\"tanh\"))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(60, activation=\"linear\"))\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95d2eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "264/264 [==============================] - 4s 13ms/step - loss: 0.1678 - mae: 0.2859 - val_loss: 0.1444 - val_mae: 0.2638\n",
      "Epoch 2/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1399 - mae: 0.2607 - val_loss: 0.1399 - val_mae: 0.2578\n",
      "Epoch 3/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1363 - mae: 0.2566 - val_loss: 0.1382 - val_mae: 0.2570\n",
      "Epoch 4/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1343 - mae: 0.2542 - val_loss: 0.1354 - val_mae: 0.2541\n",
      "Epoch 5/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1335 - mae: 0.2529 - val_loss: 0.1345 - val_mae: 0.2509\n",
      "Epoch 6/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1329 - mae: 0.2523 - val_loss: 0.1352 - val_mae: 0.2512\n",
      "Epoch 7/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1326 - mae: 0.2519 - val_loss: 0.1345 - val_mae: 0.2500\n",
      "Epoch 8/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1321 - mae: 0.2515 - val_loss: 0.1352 - val_mae: 0.2528\n",
      "Epoch 9/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1322 - mae: 0.2513 - val_loss: 0.1342 - val_mae: 0.2518\n",
      "Epoch 10/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1319 - mae: 0.2513 - val_loss: 0.1358 - val_mae: 0.2556\n",
      "Epoch 11/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1318 - mae: 0.2513 - val_loss: 0.1337 - val_mae: 0.2500\n",
      "Epoch 12/100\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.1315 - mae: 0.2509 - val_loss: 0.1341 - val_mae: 0.2504\n",
      "Epoch 13/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1314 - mae: 0.2507 - val_loss: 0.1347 - val_mae: 0.2545\n",
      "Epoch 14/100\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.1312 - mae: 0.2510 - val_loss: 0.1342 - val_mae: 0.2485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f119bc91af0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train_vec, \n",
    "          batch_size = 16,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e411634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 4ms/step - loss: 0.1367 - mae: 0.2524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1366543173789978, 0.2524428963661194]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad, y_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8d613df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['role',\n",
       "  'with',\n",
       "  'his',\n",
       "  'trademark',\n",
       "  'cock',\n",
       "  'eyed',\n",
       "  'virility',\n",
       "  'hilliard',\n",
       "  'is',\n",
       "  'an',\n",
       "  'extremely',\n",
       "  'dull',\n",
       "  'presence',\n",
       "  'and',\n",
       "  'as',\n",
       "  'a',\n",
       "  'former',\n",
       "  'band',\n",
       "  'singer',\n",
       "  'she',\n",
       "  'performs',\n",
       "  'two',\n",
       "  'berlin',\n",
       "  'love',\n",
       "  'songs',\n",
       "  'in',\n",
       "  'a',\n",
       "  'frustratingly',\n",
       "  'diffident',\n",
       "  'manner',\n",
       "  'regardless',\n",
       "  'the',\n",
       "  'magic',\n",
       "  'generated',\n",
       "  'by',\n",
       "  'astaire',\n",
       "  'and',\n",
       "  'rogers',\n",
       "  'in',\n",
       "  'their'],\n",
       " 'wants')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bdf9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 60)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad[:1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1349dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.06051656,  0.35009402,  0.26440102,  0.04520664, -0.02902132,\n",
       "        -0.17187405,  0.2417962 ,  0.33463684, -0.20373523, -0.15549763,\n",
       "         0.8187187 ,  0.11520192,  0.04938477, -0.48560056, -0.07183513,\n",
       "        -0.27102306,  0.42608008, -0.03075608, -0.6184177 , -0.19264162,\n",
       "         0.03570593, -0.41185495,  0.20316753,  0.29543114,  0.10288557,\n",
       "         0.07482363, -0.08707804,  0.20746544, -0.22759783, -0.39536488,\n",
       "         0.00853563, -0.62692666,  0.43602815, -0.09800893,  0.4056929 ,\n",
       "         0.14734806,  0.21196838, -0.46755174, -0.4296395 ,  0.01488025,\n",
       "        -0.2460854 ,  0.04334975, -0.25841773, -0.33185482,  0.2269401 ,\n",
       "         0.05472926, -0.10662878,  0.1440764 , -0.1782812 ,  0.6468891 ,\n",
       "        -0.1706374 ,  0.03132308, -0.1428622 ,  0.5371611 ,  0.3648012 ,\n",
       "         0.20618124, -0.07461578,  0.01789954,  0.25359443, -0.47009268]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_pad[:1, :, :])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e29d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af869a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('climax', 0.9883348345756531),\n",
       " ('vampire', 0.9881560802459717),\n",
       " ('writer', 0.9880637526512146),\n",
       " ('utterly', 0.987765371799469),\n",
       " ('team', 0.9875910878181458),\n",
       " ('virgin', 0.9875379800796509),\n",
       " ('comedic', 0.9873790144920349),\n",
       " ('david', 0.9873227477073669),\n",
       " ('setting', 0.9867087602615356),\n",
       " ('french', 0.9864742755889893)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ea9a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to append y_pred to X_test[0] and predict over and over to predict multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c1fe78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'climax'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word = wv.similar_by_vector(y_pred[0], topn=1)[0][0]\n",
    "new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4bb23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[0][1:]\n",
    "X_new.append(new_word)\n",
    "X_new = [X_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1af27b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48528867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new[0]), len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5559ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_embed = embedding(word2vec, X_new)\n",
    "X_new_pad = pad_sequences(X_new_embed, dtype='float32', padding='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22dbaab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 60)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "106476fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_new_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfb77796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vampire', 0.9930422902107239),\n",
       " ('comedic', 0.9919933676719666),\n",
       " ('la', 0.9912380576133728),\n",
       " ('french', 0.9912087321281433),\n",
       " ('bizarre', 0.9909916520118713),\n",
       " ('deep', 0.9908912181854248),\n",
       " ('german', 0.9905884265899658),\n",
       " ('era', 0.9905694127082825),\n",
       " ('utterly', 0.9905291795730591),\n",
       " ('animation', 0.9904189705848694)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae8f387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"he doesn't realize that his behavior should change and continues to act as he had before he listens to rap music sings along and plays the stereotypical part of an urban black man the real humor in this overall flick miss miss word extreme near awesome near awesome\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's put this into a function\n",
    "def repeat_prediction(sentence, repetition=10):\n",
    "    new_sentence = sentence\n",
    "    X = sentence.split()\n",
    "    for i in range(repetition):\n",
    "        X_embed = embedding(word2vec, [X])\n",
    "        X_pad = pad_sequences(X_embed, dtype='float32', padding='post', maxlen=40)\n",
    "        y_pred = model.predict(X_pad)\n",
    "        new_word = wv.similar_by_vector(y_pred[0], topn=1)[0][0]\n",
    "        X.pop(0)\n",
    "        X.append(new_word)\n",
    "        new_sentence += \" \" + new_word\n",
    "    return new_sentence\n",
    "\n",
    "sentence = \"he doesn't realize that his behavior should change and continues to act as he had before he listens to rap music sings along and plays the stereotypical part of an urban black man the real humor in this\"\n",
    "new_sentence = repeat_prediction(sentence)\n",
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2864956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i like this movie and the actor visual near awesome near awesome near awesome near awesome near'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"i like this movie and the actor\"\n",
    "new_sentence = repeat_prediction(sentence)\n",
    "new_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
